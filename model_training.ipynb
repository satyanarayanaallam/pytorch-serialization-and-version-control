{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad99969f-213c-40e1-870a-888689e58590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205b1c27-914d-410a-8f66-d66cf606bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x111a4f0e0>\n",
      "Epoch 0 loss 0.6970\n",
      "Epoch 1 loss 0.6870\n",
      "Epoch 2 loss 0.6818\n",
      "Epoch 3 loss 0.6807\n",
      "Epoch 4 loss 0.6777\n",
      "Epoch 5 loss 0.6770\n",
      "Epoch 6 loss 0.6736\n",
      "Epoch 7 loss 0.6722\n",
      "Epoch 8 loss 0.6746\n",
      "Epoch 9 loss 0.6739\n",
      "Epoch 10 loss 0.6722\n",
      "Epoch 11 loss 0.6702\n",
      "Epoch 12 loss 0.6697\n",
      "Epoch 13 loss 0.6714\n",
      "Epoch 14 loss 0.6712\n",
      "Epoch 15 loss 0.6688\n",
      "Epoch 16 loss 0.6711\n",
      "Epoch 17 loss 0.6681\n",
      "Epoch 18 loss 0.6711\n",
      "Epoch 19 loss 0.6700\n"
     ]
    }
   ],
   "source": [
    "%run checkpoint_script.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ea0f42-a60a-41e4-9da6-8a422a0808bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Mode\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self,in_dim=10,out_dim=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,out_dim)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c6a035-ee11-4184-861b-7d77d628b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_example(checkpoint_path=\"checkpoints/ckpt.pt\", resume=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SimpleNet().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_val = float(\"inf\")\n",
    "\n",
    "    if resume and os.path.exists(checkpoint_path):\n",
    "        ckpt = load_checkpoint(checkpoint_path, model, optimizer, scheduler, device=device)\n",
    "        start_epoch = ckpt.get(\"epoch\", 0) + 1\n",
    "        best_val = ckpt.get(\"best_metric\", best_val)\n",
    "        print(f\"Resumed from epoch {start_epoch}, best_val={best_val}\")\n",
    "\n",
    "    # Dummy dataset\n",
    "    x = torch.randn(1000, 10)\n",
    "    y = torch.randint(0, 2, (1000,))\n",
    "    ds = TensorDataset(x, y)\n",
    "    loader = DataLoader(ds, batch_size=32, shuffle=True)\n",
    "\n",
    "    for epoch in range(start_epoch, 20):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = nn.CrossEntropyLoss()(logits, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "        val_metric = total_loss / len(loader)  # placeholder for real val metric\n",
    "        print(f\"Epoch {epoch} loss {val_metric:.4f}\")\n",
    "\n",
    "        # Save checkpoint every epoch or when improved\n",
    "        is_best = val_metric < best_val\n",
    "        if is_best:\n",
    "            best_val = val_metric\n",
    "            torch.save(model.state_dict(), \"models/best_weights.pt\")\n",
    "\n",
    "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "        save_checkpoint(\n",
    "            checkpoint_path,\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler=scheduler,\n",
    "            epoch=epoch,\n",
    "            best_metric=best_val,\n",
    "            extra={\"notes\": \"example run\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66428671-3939-4c1d-a0fe-dfb9ddf5a609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.7070\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcheckpoints/ckpt.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mtrain_example\u001b[39m\u001b[34m(checkpoint_path, resume)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_best:\n\u001b[32m     41\u001b[39m     best_val = val_metric\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/best_weights.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m os.makedirs(os.path.dirname(checkpoint_path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     45\u001b[39m save_checkpoint(\n\u001b[32m     46\u001b[39m     checkpoint_path,\n\u001b[32m     47\u001b[39m     model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m     extra={\u001b[33m\"\u001b[39m\u001b[33mnotes\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mexample run\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     53\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/torch/serialization.py:966\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    963\u001b[39m     f = os.fspath(f)\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    967\u001b[39m         _save(\n\u001b[32m    968\u001b[39m             obj,\n\u001b[32m    969\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    972\u001b[39m             _disable_byteorder_record,\n\u001b[32m    973\u001b[39m         )\n\u001b[32m    974\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/torch/serialization.py:828\u001b[39m, in \u001b[36m_open_zipfile_writer\u001b[39m\u001b[34m(name_or_buffer)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    827\u001b[39m     container = _open_zipfile_writer_buffer\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/torch/serialization.py:792\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__init__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    785\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    786\u001b[39m         torch._C.PyTorchFileWriter(\n\u001b[32m    787\u001b[39m             \u001b[38;5;28mself\u001b[39m.file_stream, get_crc32_options(), _get_storage_alignment()\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     )\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    791\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_crc32_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_storage_alignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    795\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Parent directory models does not exist."
     ]
    }
   ],
   "source": [
    "train_example(checkpoint_path=\"checkpoints/ckpt.pt\", resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4844952-554a-4558-bc21-d2925acdf307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights only for inference\n",
    "torch.save(model.state_dict(), \"models/model_weights.pt\")\n",
    "\n",
    "# Load for inference\n",
    "model = SimpleNet()\n",
    "state = torch.load(\"models/model_weights.pt\", map_location=\"cpu\")\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f167b54-d209-4055-9bef-ab8a2f62f1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
