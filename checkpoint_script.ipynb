{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7aa436-9c7a-4944-add3-3041e1585360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tempfile\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290642ea-2a85-4bdb-8279-a3a350009736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    checkpoint_path: str,\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: Any = None,\n",
    "    epoch: int = 0,\n",
    "    best_metric: float = None,\n",
    "    extra: Dict[str, Any] = None,\n",
    "    *,\n",
    "    use_atomic: bool = True\n",
    ") -> None :\n",
    "    \"\"\"\n",
    "    Save a checkpoint containing model state_dict and optimizer state.\n",
    "    Writes atomically by default to avoid partial files.\n",
    "    \"\"\"\n",
    "    if extra is None:\n",
    "        extra = {}\n",
    "\n",
    "    # If model is wrapped (DataParallel / DDP), get underlying module\n",
    "    model_state = model.module.state_dict() if hasattr(model, \"module\") else model.state_dict()\n",
    "    ckpt = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model_state,\n",
    "        \"optim_state\": optimizer.state_dict(),\n",
    "        \"best_metric\": best_metric,\n",
    "        \"rng_state\": torch.get_rng_state(),\n",
    "        \"cuda_rng_state\": torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None,\n",
    "        \"extra\": extra,\n",
    "    }\n",
    "    if scheduler is not None:\n",
    "        ckpt[\"scheduler_state\"] = scheduler.state_dict()\n",
    "\n",
    "    if use_atomic:\n",
    "        dirpath = os.path.dirname(checkpoint_path) or \".\"\n",
    "        with tempfile.NamedTemporaryFile(dir=dirpath, delete=False) as tmp:\n",
    "            tmp_path = tmp.name\n",
    "        try:\n",
    "            torch.save(ckpt, tmp_path)\n",
    "            os.replace(tmp_path, checkpoint_path)  # atomic on POSIX\n",
    "        finally:\n",
    "            if os.path.exists(tmp_path):\n",
    "                os.remove(tmp_path)\n",
    "    else:\n",
    "        torch.save(ckpt, checkpoint_path)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12baa062-7d29-455b-b9aa-cb9a10598c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_check_point(\n",
    "    checkpoint_path: str,\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer = None,\n",
    "    scheduler: Any = None,\n",
    "    device: torch.device = None,\n",
    "    strict: bool = True,\n",
    "    load_optimizer: bool = True,\n",
    "    load_scheduler: bool = True,\n",
    ") -> Dict[str,Any]:\n",
    "    \"\"\"\n",
    "    Load checkpoint and restore model and optimizer/scheduler states.\n",
    "    Returns the checkpoint dict for further inspection.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    # If model is wrapped, load into underlying module\n",
    "    target_model = model.module if hasattr(model, \"module\") else model\n",
    "    target_model.load_state_dict(ckpt[\"model_state\"], strict=strict)\n",
    "\n",
    "    if optimizer is not None and load_optimizer and \"optim_state\" in ckpt:\n",
    "        try:\n",
    "            optimizer.load_state_dict(ckpt[\"optim_state\"])\n",
    "        except Exception as e:\n",
    "            # Optimizer state may be incompatible across versions; warn and continue\n",
    "            print(f\"Warning: failed to load optimizer state: {e}\")\n",
    "\n",
    "    if scheduler is not None and load_scheduler and \"scheduler_state\" in ckpt:\n",
    "        try:\n",
    "            scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: failed to load scheduler state: {e}\")\n",
    "\n",
    "    # Restore RNG states if present\n",
    "    if \"rng_state\" in ckpt and ckpt[\"rng_state\"] is not None:\n",
    "        torch.set_rng_state(ckpt[\"rng_state\"])\n",
    "    if torch.cuda.is_available() and \"cuda_rng_state\" in ckpt and ckpt[\"cuda_rng_state\"] is not None:\n",
    "        torch.cuda.set_rng_state_all(ckpt[\"cuda_rng_state\"])\n",
    "\n",
    "    return ckpt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e9beff-50ff-46ba-847c-36d675666249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fadad1c-ce9a-4aaf-b14e-2c5eb26728e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy model and data for illustration\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, in_dim=10, out_dim=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5922be27-06b0-4e3b-9f29-2e37ab8cb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_example(checkpoint_path=\"checkpoints/ckpt.pt\", resume=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SimpleNet().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_val = float(\"inf\")\n",
    "\n",
    "    if resume and os.path.exists(checkpoint_path):\n",
    "        ckpt = load_checkpoint(checkpoint_path, model, optimizer, scheduler, device=device)\n",
    "        start_epoch = ckpt.get(\"epoch\", 0) + 1\n",
    "        best_val = ckpt.get(\"best_metric\", best_val)\n",
    "        print(f\"Resumed from epoch {start_epoch}, best_val={best_val}\")\n",
    "\n",
    "    # Dummy dataset\n",
    "    x = torch.randn(1000, 10)\n",
    "    y = torch.randint(0, 2, (1000,))\n",
    "    ds = TensorDataset(x, y)\n",
    "    loader = DataLoader(ds, batch_size=32, shuffle=True)\n",
    "    print(loader)\n",
    "\n",
    "    for epoch in range(start_epoch, 20):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = nn.CrossEntropyLoss()(logits, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "        val_metric = total_loss / len(loader)  # placeholder for real val metric\n",
    "        print(f\"Epoch {epoch} loss {val_metric:.4f}\")\n",
    "\n",
    "        # Save checkpoint every epoch or when improved\n",
    "        is_best = val_metric < best_val\n",
    "        if is_best:\n",
    "            best_val = val_metric\n",
    "\n",
    "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "        save_checkpoint(\n",
    "            checkpoint_path,\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler=scheduler,\n",
    "            epoch=epoch,\n",
    "            best_metric=best_val,\n",
    "            extra={\"notes\": \"example run\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c9adbe8-902d-43dd-aa03-928eca1c23c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x110ba42f0>\n",
      "Epoch 0 loss 0.7088\n",
      "Epoch 1 loss 0.6899\n",
      "Epoch 2 loss 0.6870\n",
      "Epoch 3 loss 0.6824\n",
      "Epoch 4 loss 0.6807\n",
      "Epoch 5 loss 0.6784\n",
      "Epoch 6 loss 0.6789\n",
      "Epoch 7 loss 0.6771\n",
      "Epoch 8 loss 0.6760\n",
      "Epoch 9 loss 0.6750\n",
      "Epoch 10 loss 0.6755\n",
      "Epoch 11 loss 0.6729\n",
      "Epoch 12 loss 0.6728\n",
      "Epoch 13 loss 0.6723\n",
      "Epoch 14 loss 0.6726\n",
      "Epoch 15 loss 0.6707\n",
      "Epoch 16 loss 0.6719\n",
      "Epoch 17 loss 0.6709\n",
      "Epoch 18 loss 0.6725\n",
      "Epoch 19 loss 0.6714\n"
     ]
    }
   ],
   "source": [
    "train_example(checkpoint_path=\"checkpoints/ckpt.pt\", resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9238d-4850-44d9-b3e0-a05bf6114f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
